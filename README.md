# Rakuten Product Classification â€” MLOps (DataScientest)

Projet de pipeline MLOps complet pour la classification des produits Rakuten (texte + image) avec **traÃ§abilitÃ©**, **versioning** et **suivi d'expÃ©riences**.

## ğŸ”§ Stack (progressive)
- **Python 3.11** (venv) â€” âš ï¸ Requis pour Prefect
- **DVC** + **Dagshub** (versioning data/modÃ¨les)
- **MLflow** + **PostgreSQL** (Docker) â€” suivi d'expÃ©riences
- **Artifacts MLflow**: S3 (via variables d'environnement)
- **Prefect** (orchestration) â€” installÃ©
- **Ã€ venir** : FastAPI (serving), CI/CD GitHub Actions, Prometheus/Grafana, Evidently

## ğŸ“¦ DonnÃ©es
```
data/
â”œâ”€ raw/
â”‚  â”œâ”€ X_train.csv
â”‚  â”œâ”€ Y_train.csv
â”‚  â”œâ”€ X_test.csv
â”‚  â””â”€ images/image_train/   (fichiers: image_<imageid>*product*<productid>.jpg)
â”œâ”€ interim/
â”‚  â””â”€ merged_train.csv
â””â”€ processed/
â”œâ”€ train_features.csv
â””â”€ predictions.csv

```

## ğŸ—‚ï¸ Arborescence du repo (principal)
```
src/
â”œâ”€ data/make_dataset.py            # ingestion + contrÃ´les
â”œâ”€ features/build_features.py      # prÃ©traitement & features texte
â””â”€ models/
â”œâ”€ train_model.py               # entraÃ®nement + logs MLflow
â””â”€ predict_model.py             # infÃ©rence sur X_test
docker-compose.mlflow.yml          # MLflow + Postgres (Docker)
Dockerfile.mlflow                  # image MLflow custom (psycopg2)
dvc.yaml                           # pipeline DVC (ingestâ†’featuresâ†’trainâ†’predict)

````

## ğŸš€ DÃ©marrage rapide

### 1) Environnement Python
```bash
# Utiliser Python 3.11 (requis pour Prefect)
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2) Variables dâ€™environnement (S3 / MLflow)

CrÃ©er un fichier `.env` (non commitÃ©) :

```
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_DEFAULT_REGION=eu-west-1
# Optionnel si S3 compatible (MinIO, etc.)
# MLFLOW_S3_ENDPOINT_URL=https://s3.amazonaws.com

# Pour pointer localement (sinon dÃ©fini dans le script)
MLFLOW_TRACKING_URI=http://127.0.0.1:5000
MLFLOW_EXPERIMENT_NAME=rakuten-baseline
```

Charger dans la session :

```bash
set -a; source .env; set +a
```

### 3) Lancer MLflow (Docker)

```bash
docker compose -f docker-compose.mlflow.yml up -d
# UI: http://127.0.0.1:5000
```

### 4) Pipeline DVC (reproductible)

```bash
# exÃ©cute ingest â†’ features â†’ train â†’ predict
dvc repro
# pousse les artefacts (data/modÃ¨les) vers le remote DVC (Dagshub)
dvc push
```

### 5) Scripts unitaires

```bash
# build features
python src/features/build_features.py
# entraÃ®nement (log MLflow + artefacts S3)
python src/models/train_model.py
# prÃ©dictions sur X_test
python src/models/predict_model.py
```

## ğŸ§­ Bonnes pratiques & traÃ§abilitÃ©

* **MLflow** : chaque run logue paramÃ¨tres, mÃ©triques et artefacts (modÃ¨le, vectorizer, metrics.json).
  Des tags lient le run au **commit Git** (`git_commit`, `git_branch`) et la run joint `dvc.yaml`/`dvc.lock`.
* **DVC** : gÃ¨re les outputs de pipeline (`data/interim`, `data/processed`, `models/*`) et synchronise vers Dagshub.
* **Branches** : travail sur `feat/seba/bootstrap` puis PR vers `main`.

## ğŸ†˜ DÃ©pannage rapide

* **S3 auth fail** : vÃ©rifier `.env` chargÃ© dans le shell (`set -a; source .env; set +a`) et droits IAM.
* **MLflow artifacts en erreur** : vÃ©rifier que le compose utilise `/home/mlflow/artifacts` et que le dossier local `./mlruns` existe.
* **DVC â€œtracked by SCMâ€** : retirer du suivi Git (`git rm -r --cached <fichier>`) avant de dÃ©clarer en output DVC.
* **Images manquantes** : le chemin attendu est `data/raw/images/image_train/` avec le motif `image_<imageid>_product_<productid>.jpg`.

## ğŸ“Œ Licence

Voir `LICENSE`.
MD

```

